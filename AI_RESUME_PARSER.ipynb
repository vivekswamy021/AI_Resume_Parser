{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKmznj9stNDzpmu8Q7m5Hu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekswamy021/AI_Resume_Parser/blob/main/AI_RESUME_PARSER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio python-docx pdfplumber openpyxl pandas  requests groq"
      ],
      "metadata": {
        "id": "mDS3-D60N81Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc02da4f-92ae-4dd3-b782-01c446a01ef2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.32.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.26.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "import gradio as gr\n",
        "import os\n",
        "import pdfplumber\n",
        "import docx\n",
        "import openpyxl\n",
        "import json\n",
        "import tempfile\n",
        "from groq import Groq\n",
        "\n",
        "\n",
        "# GROQ-SETUP\n",
        "client = Groq(api_key=\"Add Groq API Key\")\n",
        "\n",
        "\n",
        "#  Identify file type\n",
        "def get_file_type(file_path):\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext == '.pdf':\n",
        "        return 'pdf'\n",
        "    elif ext == '.docx':\n",
        "        return 'docx'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "#  Extract content\n",
        "def extract_content(file_type, file_path):\n",
        "    try:\n",
        "        if file_type == 'pdf':\n",
        "            text = ''\n",
        "            with pdfplumber.open(file_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + '\\n'\n",
        "            return text\n",
        "        elif file_type == 'docx':\n",
        "            doc = docx.Document(file_path)\n",
        "            return '\\n'.join([para.text for para in doc.paragraphs])\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Extraction error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "#Parsing Function with LLM\n",
        "def parse_with_llm(text, return_type='json'):\n",
        "    prompt = f\"\"\"Extract the following information from the resume in structured JSON:\n",
        "    - Name\n",
        "    - Email\n",
        "    - Phone\n",
        "    - Skills\n",
        "    - Education\n",
        "    - Experience\n",
        "    - Certifications\n",
        "    - Projects\n",
        "    - strength\n",
        "    - Personal Details\n",
        "    - Github\n",
        "    - linkedin\n",
        "\n",
        "    Resume:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.2)\n",
        "\n",
        "    content = response.choices[0].message.content.strip()\n",
        "\n",
        " # Try to extract JSON from the response\n",
        "    json_start = content.find('{')\n",
        "    json_end = content.rfind('}') + 1\n",
        "    if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "        json_str = content[json_start:json_end]\n",
        "    else:\n",
        "        json_str = content\n",
        "    try:\n",
        "        parsed = json.loads(json_str)\n",
        "    except Exception:\n",
        "        parsed = {\"error\": \"Invalid JSON\", \"raw_output\": content}\n",
        "    if return_type == 'json':\n",
        "        return parsed\n",
        "    elif return_type == 'markdown':\n",
        "        # Convert parsed JSON to Markdown\n",
        "        if \"error\" in parsed:\n",
        "            return f\"**Error:** {parsed.get('raw_output','')}\"\n",
        "        md = \"\"\n",
        "        for k, v in parsed.items():\n",
        "            if isinstance(v, list):\n",
        "                md += f\"**{k.title()}**:\\n\"\n",
        "                for item in v:\n",
        "                    md += f\"- {item}\\n\"\n",
        "            else:\n",
        "                md += f\"**{k.title()}**: {v}\\n\\n\"\n",
        "        return md\n",
        "    else:\n",
        "        return {\"error\": \"Invalid return_type\"}\n",
        "\n",
        "\n",
        "\n",
        "#def dump_to_excel(parsed_json, filename):\n",
        "import openpyxl\n",
        "def dump_to_excel(parsed_json, filename):\n",
        "    wb = openpyxl.Workbook()\n",
        "    ws = wb.active\n",
        "    ws.title = \"Profile\"\n",
        "    row = 1\n",
        "\n",
        "    # Basic info\n",
        "    for field in ['name', 'email', 'phone']:\n",
        "        if field in parsed_json:\n",
        "            ws.cell(row=row, column=1, value=field.title())\n",
        "            ws.cell(row=row, column=2, value=parsed_json[field])\n",
        "            row += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Flexible key matching map\n",
        "    section_map = {\n",
        "        'Skills': ['skills'],\n",
        "        'Education': ['education'],\n",
        "        'Experience': ['experience'],\n",
        "        'Certifications': ['certifications'],\n",
        "        'Projects': ['projects'],\n",
        "        'Strength': ['strength', 'strengths'],\n",
        "        'Personal Details': ['Personal_Details'],\n",
        "        'Github': ['github'],\n",
        "        'LinkedIn': ['linkedin'],\n",
        "        'Email': ['email']}\n",
        "\n",
        "    for section_title, key_variants in section_map.items():\n",
        "        matched_key = next((k for k in parsed_json if k.lower() in [v.lower() for v in key_variants]), None)\n",
        "\n",
        "        if matched_key and parsed_json[matched_key]:\n",
        "            ws.cell(row=row, column=1, value=section_title)\n",
        "            row += 1\n",
        "            content = parsed_json[matched_key]\n",
        "\n",
        "            if isinstance(content, list):\n",
        "                for item in content:\n",
        "                    ws.cell(row=row, column=2, value=str(item))\n",
        "                    row += 1\n",
        "            elif isinstance(content, dict):\n",
        "                for k, v in content.items():\n",
        "                    ws.cell(row=row, column=2, value=f\"{k}: {v}\")\n",
        "                    row += 1\n",
        "            else:\n",
        "                ws.cell(row=row, column=2, value=str(content))\n",
        "                row += 1\n",
        "        else:\n",
        "            print(f\" Skipping section '{section_title}' â€” not found or empty.\")\n",
        "\n",
        "    wb.save(filename)\n",
        "\n",
        "\n",
        "#  Main Parser Function\n",
        "def ParserCV(file_type, file_path, return_type='json'):\n",
        "    text = extract_content(file_type, file_path)\n",
        "    if not text:\n",
        "        return {\"error\": \"Unable to extract content from the file.\"}, text, None\n",
        "    parsed = parse_with_llm(text, return_type='json')\n",
        "    if not parsed or \"error\" in parsed:\n",
        "        return parsed, text, None\n",
        "    # Name Excel file after candidate\n",
        "    name = parsed.get('name', 'candidate').replace(' ', '_')\n",
        "    excel_filename = os.path.join(tempfile.gettempdir(), f\"{name}.xlsx\")\n",
        "    dump_to_excel(parsed, excel_filename)\n",
        "    if return_type == 'json':\n",
        "        return parsed, text, excel_filename\n",
        "    elif return_type == 'markdown':\n",
        "        return parse_with_llm(text, return_type='markdown'), text, excel_filename\n",
        "    else:\n",
        "        return {\"error\": \"Invalid return_type.\"}, text, None\n",
        "\n",
        "#  Gradio UI\n",
        "def gradio_interface(file, output_format, section):\n",
        "    file_path = file.name\n",
        "    file_type = get_file_type(file_path)\n",
        "    parsed, full_text, excel_path = ParserCV(file_type, file_path, return_type='json')\n",
        "\n",
        "\n",
        "    # Section extraction\n",
        "    section_content = \"\"\n",
        "    section_file = None\n",
        "    if not parsed or \"error\" in parsed:\n",
        "        main_output = parsed.get(\"error\", \"Unknown error\")\n",
        "        json_output = json.dumps(parsed, indent=2)\n",
        "        markdown_output = main_output\n",
        "        excel_path = None\n",
        "        section_content = parsed.get(\"raw_output\", \"\")\n",
        "    else:\n",
        "        json_output = json.dumps(parsed, indent=2)\n",
        "        markdown_output = parse_with_llm(full_text, return_type='markdown')\n",
        "        main_output = json_output if output_format == \"json\" else markdown_output\n",
        "\n",
        "\n",
        "        # Section logic\n",
        "        if section == \"full resume\":\n",
        "            section_content = full_text\n",
        "        elif section == \"raw output\":\n",
        "            section_content = json_output\n",
        "        elif section == \"download raw output\":\n",
        "            tmp_raw = tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\")\n",
        "            tmp_raw.write(json_output.encode('utf-8'))\n",
        "            tmp_raw.close()\n",
        "            section_file = tmp_raw.name\n",
        "        elif section in parsed:\n",
        "            section_val = parsed[section]\n",
        "            section_content = json.dumps(section_val, indent=2) if isinstance(section_val, (list, dict)) else str(section_val)\n",
        "        else:\n",
        "            section_content = f\"Section '{section}' not found.\"\n",
        "\n",
        "\n",
        "\n",
        "    # Return outputs\n",
        "    if section == \"download raw output\" and section_file:\n",
        "        return main_output, excel_path, section_file\n",
        "    else:\n",
        "        return main_output, excel_path, section_content\n",
        "\n",
        "\n",
        "# Section options for dropdown\n",
        "section_options = [\n",
        "    \"name\", \"email\", \"experience\", \"projects\", \"skills\",\n",
        "    \"education\", \"full resume\",\"github\",\"linkedin\"]\n",
        "\n",
        "with gr.Blocks(title=\"AI Resume Parser\") as demo:\n",
        "    gr.Markdown(\"## AI Resume Parser (PDF/DOCX) with Groq and Gradio\")\n",
        "    with gr.Row():\n",
        "        file_input = gr.File(label=\"Upload Resume (PDF/DOCX)\", file_types=[\".pdf\", \".docx\"])\n",
        "        output_format = gr.Radio(['json', 'markdown'], label=\"Output Format\", value=\"json\")\n",
        "        section = gr.Dropdown(section_options, label=\"Section\", value=\"full resume\")\n",
        "    main_output = gr.Textbox(label=\"Parsed Output (JSON/Markdown)\", lines=20)\n",
        "    excel_output = gr.File(label=\"Download Excel\")\n",
        "    section_output = gr.Textbox(label=\"Section Output\", lines=10)\n",
        "    section_file_output = gr.File(label=\"Download Section Output\", visible=False)\n",
        "\n",
        "\n",
        "    # Interface wrapper\n",
        "    def wrapped_interface(file, output_format, section):\n",
        "        result = gradio_interface(file, output_format, section)\n",
        "        # result: main_output, excel_path, section_content/section_file\n",
        "        if section == \"download raw output\" and result[2]:\n",
        "            return result[0], result[1], gr.update(visible=False), result[2]\n",
        "        else:\n",
        "            return result[0], result[1], result[2], gr.update(visible=False)\n",
        "\n",
        "\n",
        "    # Bind input changes to wrapped_interface to update outputs\n",
        "    file_input.change(\n",
        "        wrapped_interface,\n",
        "        inputs=[file_input, output_format, section],\n",
        "        outputs=[main_output, excel_output, section_output, section_file_output])\n",
        "\n",
        "    output_format.change(\n",
        "        wrapped_interface,\n",
        "        inputs=[file_input, output_format, section],\n",
        "        outputs=[main_output, excel_output, section_output, section_file_output])\n",
        "\n",
        "    section.change(\n",
        "        wrapped_interface,\n",
        "        inputs=[file_input, output_format, section],\n",
        "        outputs=[main_output, excel_output, section_output, section_file_output])\n",
        "\n",
        "    demo.load(lambda: (\"\", None, \"\", None),\n",
        "                inputs=None,\n",
        "                outputs=[main_output, excel_output, section_output, section_file_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "ak4rpOABXebV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "0e3f8f5d-76ee-4e8e-b54e-746c817a5987"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://37e1eaf2df7b77bb74.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://37e1eaf2df7b77bb74.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKKd8l0hXfNw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mstXtyvxewK6"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}